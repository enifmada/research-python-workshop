{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa75745e-e2f9-4633-8558-e345aeed43f9",
   "metadata": {},
   "source": [
    "## Problem 1: PyPy's Pizzeria\n",
    "\n",
    "Congratulations! Due to your success in determining which pizza-making function calls are valid on Homework 1, you have been put in charge of the codebase of PyPy's Pizzeria, a fast-growing chain. Unfortunately, the previous backend engineer didn't know anything about Numpy. This was fine when there was only PyPy's Pizzeria, but their code base simply can't handle 100000 orders coming in at once!\n",
    "\n",
    "Using all the techniques we discussed in class **other than njit** (profiling to identify bottlenecks -> vectorization + reducing function calls), speed up the pizza-making code so that the combined runtime of the functions take_orders(n=100000) and compute_overhead(orders) runs in under 1 second. **Note that the sample output is currently for 10k orders - do not attempt to run the code for 100k orders until it is significantly optimized.** You don't have to preserve anything about the formatting of the internal variables (e.g. take_orders can return whatever you like) as long as the overall result of the code is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df1224-41b1-4c6b-ae47-d32c2e1e055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(6)\n",
    "\n",
    "toppings = [\"pepperoni\", \"sausage\", \"ham\", \"chicken\", \"mushrooms\", \"pineapple\", \"peppers\", \"spinach\", \"onion\", \"olives\", \"extra cheese\", \"extra sauce\"]\n",
    "topping_probs = [.3, .4, .2, .3, .6, .05, .2, .25, .45, .3, .35, .35]\n",
    "topping_costs = [2.0, 1.5, 3.0, 2.5, 1.0, 1.0, 1.5, 1.5, 1.0, 2.0, 3.0, 2.5]\n",
    "\n",
    "prob_deepdish = .6 #deal with it\n",
    "prob_detroitstyle = .1\n",
    "\n",
    "base_cost = 10.0\n",
    "\n",
    "def take_orders(n_customers=10000):\n",
    "    #returns a list of each pizza's toppings, type, cost, and bake time\n",
    "\n",
    "    orders = []\n",
    "    for i in range(n_customers):\n",
    "        order_list = []\n",
    "        toppings_list = []\n",
    "\n",
    "        for topping in toppings:\n",
    "            topping_rand = random.random()\n",
    "            if topping_rand < topping_probs[toppings.index(topping)]:\n",
    "                toppings_list.append(topping)\n",
    "        order_list.append(toppings_list)\n",
    "\n",
    "        #type\n",
    "        type_rand = random.random()\n",
    "        if type_rand < prob_deepdish:\n",
    "            order_list.append(\"Deep dish\")\n",
    "        elif type_rand < prob_deepdish + prob_detroitstyle:\n",
    "            order_list.append(\"Detroit style\")\n",
    "        else:\n",
    "            order_list.append(\"New York style\")\n",
    "\n",
    "        #cost - intentionally written very badly\n",
    "        cost = base_cost\n",
    "        for topping in toppings:\n",
    "            if topping in toppings_list:\n",
    "                topping_index = toppings.index(topping)\n",
    "                cost += topping_costs[topping_index]\n",
    "\n",
    "        #deluxe surcharge\n",
    "        if len(toppings_list) > 2:\n",
    "            cost += 2.0\n",
    "\n",
    "        order_list.append(cost)\n",
    "        \n",
    "        #bake times\n",
    "        if order_list[1] == \"Deep dish\":\n",
    "            order_list.append(45)\n",
    "        elif order_list[1] == \"Detroit style\":\n",
    "            order_list.append(25)\n",
    "        else:\n",
    "            order_list.append(10)\n",
    "\n",
    "        orders.append(order_list)\n",
    "    return orders\n",
    "\n",
    "\n",
    "def compute_overhead(n_orders):\n",
    "    n = len(n_orders)\n",
    "    revenue = 0\n",
    "\n",
    "    toppings_used = [0]*len(toppings)\n",
    "    for order_i in n_orders:\n",
    "        revenue += order_i[-2]\n",
    "        for topping in toppings:\n",
    "            if topping in order_i[0]:\n",
    "                toppings_used[toppings.index(topping)] += 1\n",
    "\n",
    "    print(f\"Total revenue from {n} customers: {revenue:.2f}.\")\n",
    "    print(\"Total ingredients used:\")\n",
    "    for topping in toppings:\n",
    "        print(f\"{toppings_used[toppings.index(topping)]} {topping}.\")\n",
    "    \n",
    "    #make a histogram of the numbers of different types of pizzas ordered\n",
    "    same_pizzas = []\n",
    "    for order_i in n_orders:\n",
    "        num_same = 0\n",
    "        for order_j in n_orders:\n",
    "            for order_component_idx in range(len(order_i)):\n",
    "                if order_i[order_component_idx] != order_j[order_component_idx]:\n",
    "                    break\n",
    "                num_same += 1\n",
    "        same_pizzas.append(num_same)\n",
    "\n",
    "    plt.hist(same_pizzas)\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be123-6346-4609-966a-f848c9593b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "orders = take_orders(10000)\n",
    "compute_overhead(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41917fa",
   "metadata": {},
   "source": [
    "## Problem 2: Hmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
    "\n",
    "As discussed in minimal mathematical detail at the Advance, my work heavily uses the Hidden Markov Model (HMM). The following code implements a generic HMM in not-very-optimized form, as well as providing some short test cases with which to benchmark its speed.\n",
    "\n",
    "Inspired by my life circa May 2022, your task is to optimize the code! \n",
    "\n",
    "To do this effectively, learning a thing or two about HMMs may be of use (or not - sometimes it can be more effective to just treat code as code and optimize away). [This page](https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf) is the standard introduction to HMMs - readable but concise. Only sections I-III are relevant (you can stop when you get to \"IV - Types of HMMs\" on page 10). In addition, the Wikipedia page for HMMs is pretty good. I use the notation from [the \"weather guessing game\" section](https://en.wikipedia.org/wiki/Hidden_Markov_model#Weather_guessing_game) to contextualize the benchmark samples.\n",
    "\n",
    "Profile, vectorize, reduce function calls, numba, repeat to your heart's content!\n",
    "\n",
    "Once you feel like your code is reasonably optimized, run the final cell, which does 50000 iterations.\n",
    "\n",
    "Note that if you choose to do this in a jupyter notebook, you can still use snakeviz with the\n",
    "%load_ext snakeviz and %%snakeviz -t commands.\n",
    "\n",
    "Also note that numba is of course useful but not the only way to achieve significant speedups - my optimized code is roughly 3x faster than just adding @njit to everything.\n",
    "\n",
    "Good luck! This will take a while but trust me it's worth it - optimizing my pop-gen HMM was basically how I learned about all of this stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6745b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#equations 18-21 in Rabiner\n",
    "def forward_algo(A_matrix, B_matrix, pi, O):\n",
    "    T = O.shape[0]\n",
    "    alphas = np.zeros((pi.shape[0], T))\n",
    "    alphas[:, 0] = pi * B_matrix[:, O[0]]\n",
    "    for t in np.arange(1, T):\n",
    "        for j in np.arange(alphas.shape[0]):\n",
    "            alphas[j, t] = np.sum(A_matrix[:, j] * alphas[:, t - 1]) * B_matrix[j, O[t]]\n",
    "    return alphas\n",
    "\n",
    "#equations 23-25 in Rabiner\n",
    "def backward_algo(A_matrix, B_matrix, pi, O):\n",
    "    T = O.shape[0]\n",
    "    betas = np.zeros((pi.shape[0], T))\n",
    "    betas[:, -1] = 1\n",
    "    for t in np.arange(1, T):\n",
    "        for i in np.arange(betas.shape[0]):\n",
    "            betas[i, -(t + 1)] = np.sum(A_matrix[i, :] * B_matrix[:, O[-t]] * betas[:, -t])\n",
    "    return betas\n",
    "\n",
    "#equations 26-28 in Rabiner\n",
    "def compute_gammas(alphas, betas):\n",
    "    gammas = alphas * betas\n",
    "    gammas /= np.sum(gammas, axis=0)\n",
    "    assert np.all(np.isclose(np.sum(gammas, axis=0), 1))\n",
    "    return gammas\n",
    "\n",
    "#equations 36-38 in Rabiner\n",
    "def compute_xis(alphas, betas, A_matrix, B_matrix, O):\n",
    "    xis = np.zeros((alphas.shape[0], alphas.shape[0], alphas.shape[1] - 1))\n",
    "    for t in np.arange(alphas.shape[1] - 1):\n",
    "        for i in np.arange(alphas.shape[0]):\n",
    "            for j in np.arange(alphas.shape[0]):\n",
    "                xis[i, j, t] = alphas[i, t] * A_matrix[i, j] * B_matrix[j, O[t + 1]] * betas[j, t + 1]\n",
    "    xis /= np.sum(np.sum(xis, axis=0),axis=0)\n",
    "    return xis\n",
    "\n",
    "#equations 40a-c in Rabiner\n",
    "def update_params(gammas, xis, A_matrix, B_matrix, O, pi):\n",
    "    pi_new = gammas[:, 0]\n",
    "    A_matrix_new = np.zeros_like(A_matrix)\n",
    "    B_matrix_new = np.zeros_like(B_matrix)\n",
    "    for j in np.arange(A_matrix_new.shape[0]):\n",
    "        A_matrix_new[:, j] = np.sum(xis[:, j, :], axis=1) / np.sum(gammas[:, :-1], axis=1)\n",
    "\n",
    "    for k in np.arange(B_matrix_new.shape[1]):\n",
    "        obs_mask = O == k\n",
    "        B_matrix_new[:, k] = np.sum(gammas[:, obs_mask], axis=1) / np.sum(gammas, axis=1)\n",
    "\n",
    "    return pi_new, A_matrix_new, B_matrix_new\n",
    "\n",
    "\n",
    "\n",
    "### these two functions are probably less optimizable, since they're just calling the above functions\n",
    "\n",
    "#defines the forward/backward -> gamma + xis -> parameter re-estimation loop\n",
    "def run_one_iter(A_matrix, B_matrix, pi, O):\n",
    "    alphas = forward_algo(A_matrix, B_matrix, pi, O)\n",
    "    betas = backward_algo(A_matrix, B_matrix, pi, O)\n",
    "    gammas = compute_gammas(alphas, betas)\n",
    "    xis = compute_xis(alphas, betas, A_matrix, B_matrix, O)\n",
    "    assert np.all(np.isclose(np.sum(xis, axis=1), gammas[:, :-1]))\n",
    "    pi_new, A_matrix_new, B_matrix_new = update_params(gammas, xis, A_matrix, B_matrix, O, pi)\n",
    "    return pi_new, A_matrix_new, B_matrix_new, np.sum(alphas[:, -1])\n",
    "\n",
    "#iterates run_one_iter, checks if the likelihood has converged, repeats\n",
    "def run_hmm(A_init, B_init, pi_init, O, tol, max_iter):\n",
    "    pi, A, B = pi_init, A_init, B_init\n",
    "    itercount = 0\n",
    "    likelihood = -np.inf\n",
    "    while itercount < max_iter:\n",
    "        pi, A, B, ll_new = run_one_iter(A, B, pi, O)\n",
    "        if ll_new - likelihood < tol:\n",
    "            return pi, A, B, ll_new\n",
    "        likelihood = ll_new\n",
    "        itercount += 1\n",
    "    print(\"failed to converge!\")\n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial distribution of the hidden variable - is day 1 sunny, cloudy, or rainy?\n",
    "pi_init = np.array([0.1, 0.1, 0.8])\n",
    "\n",
    "#initial transition matrix - P([sunny -> sunny, sunny -> cloudy, sunny -> rainy], etc)\n",
    "A_init = np.array([[0.5, 0.4, 0.1], [0.3, 0.4, 0.3], [0.1, 0.45, 0.45]])\n",
    "\n",
    "#initial emission matrix - P([activity 1, activity 2, activity 3...]|sunny, etc)\n",
    "B_init = np.array([[.2, .1, .3, .25, .15], [.4, .15, .3, .1, .05], [0.6, .2, .198, 0.001, 0.001]])\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "#set up a random series of fake observations\n",
    "obs_array = rng.choice([0,1,2,3,4], (1000, 250), replace=True)\n",
    "tol = 1e-8\n",
    "max_iter = 100\n",
    "\n",
    "for i in tqdm(np.arange(obs_array.shape[0])):\n",
    "    pi_final, A_final, B_final, ll_final = run_hmm(A_init, B_init, pi_init, obs_array[i, :], tol, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### final test - don't run initially it will be pretty slow\n",
    "obs_array = rng.choice([0,1,2,3,4], (50000, 250), replace=True)\n",
    "tol = 1e-8\n",
    "max_iter = 100\n",
    "\n",
    "for i in tqdm(np.arange(obs_array.shape[0])):\n",
    "    pi_final, A_final, B_final, ll_final = run_hmm(A_init, B_init, pi_init, obs_array[i, :], tol, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24447b61-b856-4923-9f9c-e7caa12774e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
